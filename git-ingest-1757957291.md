# 🚀 Project Analysis Report

Directory structure for: betterprompt

## 🎯 LLM-Optimized Codebase Analysis

This document provides a comprehensive, structured analysis of the codebase optimized for 
Large Language Model (LLM) processing. The content is organized with semantic markup, 
proper syntax highlighting, and hierarchical structure for enhanced AI comprehension.

## 📑 Table of Contents

- [📊 Project Overview](#-project-overview)
- [📈 Statistics](#-statistics)
- [🏗️ Directory Structure](#️-directory-structure)
- [📁 Files by Category](#-files-by-category)
  - [🌐 Web Frontend](#1f310-web-frontend)
  - [⚙️ Data/Config](#2699-data-config)
  - [📖 Documentation](#1f4d6-documentation)
- [📋 Complete File Listing](#-complete-file-listing)

## 📊 Project Overview

**Project:** `betterprompt`  
**Path:** `/Users/aungmyokyaw/Desktop/life/repos/tools/servers/src/betterprompt`  
**Generated:** 2025-09-15T17:28:11.818Z  
**Total Files:** 12  
**Total Size:** 50.9 KB  

### 🎯 Quick Summary

This document contains a comprehensive analysis of the **betterprompt** project, 
including its complete directory structure and the full content of all text files. 
The content is organized in a hierarchical, LLM-friendly format with proper syntax 
highlighting and metadata for optimal AI processing.

## 📈 Statistics

### 📊 File Type Distribution

| Category | Files | Percentage |
| --- | --- | --- |
| Web Frontend | 9 | 75.0% |
| Data/Config | 2 | 16.7% |
| Documentation | 1 | 8.3% |

### 💻 Programming Languages

| Language | Files | Primary Category |
| --- | --- | --- |
| javascript | 8 | Web Frontend |
| json | 2 | Data/Config |
| markdown | 1 | Documentation |
| typescript | 1 | Web Frontend |

### 📏 Size Analysis

- **Total Project Size:** 50.9 KB
- **Average File Size:** 4.2 KB
- **Text Files:** 12 (100.0%)

## 🏗️ Directory Structure

```
├── dist-test
│   └── test.js
├── agent-test.js
├── final-verification.js
├── index.ts
├── integration-test.js
├── package.json
├── README.md
├── test-all-techniques.js
├── test-auto-enhancement.js
├── test-betterprompt.js
├── test.js
└── tsconfig.json
```

## 📁 Files by Category

### 🌐 Web Frontend

**Languages:** javascript, typescript  
**File Count:** 9

### ⚙️ Data/Config

**Languages:** json  
**File Count:** 2

### 📖 Documentation

**Languages:** markdown  
**File Count:** 1
## 📋 Complete File Listing

The following section contains the complete content of all text files in the project, 
organized with proper syntax highlighting and metadata for optimal LLM processing.

### 📄 `README.md`

**Path:** `README.md`  
**Size:** 5.6 KB  
**Language:** markdown (medium confidence)  
**Category:** Documentation  
```markdown
# BetterPrompt MCP Server

An MCP (Model Context Protocol) server that automatically rephrases all user prompts using world-class prompt engineering techniques to make them more effective when used with AI models.

## Overview

The BetterPrompt server enhances all prompts automatically using various advanced prompt engineering techniques developed by leading AI research institutions including Anthropic, OpenAI, and Google DeepMind. It helps users create more effective prompts that produce better results from AI models without requiring explicit tool invocation.

Unlike other MCP tools that need to be explicitly called, BetterPrompt automatically processes every user request, improving the underlying prompt before it's sent to the AI model. By default, the server uses Sequential Thinking approach which mimics how world-class prompt engineers think through problems adaptively.

## Features

The server implements the following advanced prompt engineering techniques:

- **Chain-of-Thought**: Breaking down complex requests into step-by-step reasoning
- **Role Prompting**: Assigning expert roles to guide responses
- **Few-Shot Learning**: Providing examples to demonstrate desired output
- **Tree-of-Thoughts**: Exploring multiple reasoning paths simultaneously
- **ReAct (Reasoning + Action)**: Combining reasoning and action-taking
- **Reflexion**: Enabling self-reflection and iterative improvement
- **Generate Knowledge**: Instructing models to generate relevant background information
- **Prompt Chaining**: Breaking complex tasks into sequential steps
- **Self-Consistency**: Generating multiple reasoning paths and selecting the most consistent answer
- **Sequential Thinking**: Applying adaptive, step-by-step thinking like expert problem solvers
- **Comprehensive**: Combining multiple techniques for maximum effectiveness

## Installation

### From npm

```bash
npm install @modelcontextprotocol/server-betterprompt
```

### Local Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd servers/src/betterprompt
```

2. Install dependencies:
```bash
npm install
```

3. Build the project:
```bash
npm run build
```

4. Link globally (optional):
```bash
npm link
```

### Using the MCP

To use this MCP with an MCP-compatible client:

1. Ensure the server is installed and built
2. Run the server:
```bash
npx mcp-server-betterprompt
```
3. Connect your MCP client to the server

If you've linked it globally, you can run:
```bash
mcp-server-betterprompt
```

Once connected, BetterPrompt will automatically enhance all user prompts without requiring explicit tool invocation.

## Usage

### Running the Server

```bash
npx mcp-server-betterprompt
```

Or if installed globally:

```bash
mcp-server-betterprompt
```

### How It Works

BetterPrompt automatically processes every user request without requiring explicit invocation. When a user sends any prompt, the server:

1. Intercepts the prompt before it reaches the AI model
2. Rephrases it using advanced prompt engineering techniques
3. Sends the enhanced prompt to the AI model
4. Returns the result to the user

Users don't need to explicitly call the `betterprompt` tool - it works automatically on all requests.

### Using the Tool Explicitly

While BetterPrompt works automatically, you can still explicitly call the tool with specific parameters:

```json
{
  "prompt": "The original prompt to rephrase",
  "technique": "The prompt engineering technique to use (optional, defaults to 'comprehensive')"
}
```

Available techniques:
- `chain-of-thought`
- `role`
- `few-shot`
- `tree-of-thoughts`
- `react`
- `reflexion`
- `generate-knowledge`
- `prompt-chaining`
- `self-consistency`
- `sequential-thinking` (default)
- `comprehensive`

### Example Requests

Since BetterPrompt works automatically, users simply interact with the AI as normal:

```
User: Explain quantum computing
```

BetterPrompt automatically enhances this request before sending it to the AI model.

Explicit tool usage:
```json
{
  "name": "betterprompt",
  "arguments": {
    "prompt": "Write a marketing copy for a new smartphone",
    "technique": "few-shot"
  }
}
```

## Development

### Building

```bash
npm run build
```

This command will:
1. Compile TypeScript files to JavaScript in the `dist` directory
2. Make the output files executable

### Running in Watch Mode

```bash
npm run watch
```

This command will continuously compile TypeScript files as they change.

### Testing

```bash
node test.js
```

## How It Works

The server implements specialized rephrasing functions for each technique:

1. **Chain-of-Thought**: Rephrases prompts to include sequential reasoning steps
2. **Role Prompting**: Assigns specific expert roles with detailed credentials
3. **Few-Shot**: Adds sophisticated examples to demonstrate the desired approach
4. **Tree-of-Thoughts**: Structures prompts to explore multiple reasoning paths
5. **ReAct**: Formats prompts for interleaved reasoning and action steps
6. **Reflexion**: Adds self-evaluation and iterative improvement components
7. **Generate Knowledge**: Includes steps to generate relevant background information
8. **Prompt Chaining**: Breaks complex tasks into sequential sub-prompts
9. **Self-Consistency**: Structures prompts to generate multiple reasoning paths
10. **Sequential Thinking**: Applies adaptive, step-by-step thinking like expert problem solvers
11. **Comprehensive**: Combines multiple techniques for maximum effectiveness

Each technique is designed to leverage the latest research in prompt engineering to produce more effective prompts. By default, the server uses Sequential Thinking which mimics how world-class prompt engineers approach problems.

## License

MIT

## Author

Anthropic, PBC (https://anthropic.com)
```

### 📄 `agent-test.js`

**Path:** `agent-test.js`  
**Size:** 2.4 KB  
**Language:** javascript (medium confidence)  
**Category:** Web Frontend  
```javascript
#!/usr/bin/env node

import { spawn } from 'child_process';

async function testBetterPromptInAgentContext() {
  console.log('Testing BetterPrompt MCP in Coding Agent Context...');
  
  // Spawn the server process
  const server = spawn('node', ['dist/index.js'], {
    stdio: ['pipe', 'pipe', 'pipe']
  });

  // Promise to capture the response
  let responsePromiseResolve;
  const responsePromise = new Promise((resolve) => {
    responsePromiseResolve = resolve;
  });

  // Collect server output
  let serverOutput = '';
  
  server.stdout.on('data', (data) => {
    serverOutput += data.toString();
    // Try to parse JSON responses
    const lines = data.toString().split('\n');
    for (const line of lines) {
      if (line.trim()) {
        try {
          const response = JSON.parse(line);
          if (response.result && response.result.content) {
            responsePromiseResolve(response.result.content[0].text);
          }
        } catch (e) {
          // Not a JSON line, ignore
        }
      }
    }
  });

  server.stderr.on('data', (data) => {
    console.log(`[Server stderr] ${data}`);
  });

  // Wait a bit for the server to start
  await new Promise(resolve => setTimeout(resolve, 1000));

  // Simulate how an agent would use the betterprompt tool
  console.log('\n--- Agent Usage Test ---');
  
  // Example 1: Agent wants to improve a code generation prompt
  const codePrompt = "Write a Python function to sort a list of dictionaries by a specific key";
  console.log(`Original prompt: "${codePrompt}"`);
  
  const betterPromptRequest = {
    jsonrpc: "2.0",
    id: 1,
    method: "tools/call",
    params: {
      name: "betterprompt",
      arguments: {
        prompt: codePrompt
      }
    }
  };

  server.stdin.write(JSON.stringify(betterPromptRequest) + '\n');
  
  // Wait for and capture the response
  const enhancedPrompt = await Promise.race([
    responsePromise,
    new Promise(resolve => setTimeout(() => resolve(null), 3000))
  ]);
  
  if (enhancedPrompt) {
    console.log('\nEnhanced prompt:');
    console.log(enhancedPrompt);
    console.log('\n--- Test Result: PASS ---');
  } else {
    console.log('\n--- Test Result: FAIL ---');
    console.log('No response received from betterprompt tool');
  }

  // Close the server
  server.kill();
  
  console.log('\nAgent context test completed!');
}

testBetterPromptInAgentContext().catch(console.error);
```

### 📄 `test.js`

**Path:** `dist-test/test.js`  
**Size:** 4.8 KB  
**Language:** javascript (medium confidence)  
**Category:** Web Frontend  
```javascript
#!/usr/bin/env node
"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __generator = (this && this.__generator) || function (thisArg, body) {
    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g = Object.create((typeof Iterator === "function" ? Iterator : Object).prototype);
    return g.next = verb(0), g["throw"] = verb(1), g["return"] = verb(2), typeof Symbol === "function" && (g[Symbol.iterator] = function() { return this; }), g;
    function verb(n) { return function (v) { return step([n, v]); }; }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while (g && (g = 0, op[0] && (_ = 0)), _) try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [op[0] & 2, t.value];
            switch (op[0]) {
                case 0: case 1: t = op; break;
                case 4: _.label++; return { value: op[1], done: false };
                case 5: _.label++; y = op[1]; op = [0]; continue;
                case 7: op = _.ops.pop(); _.trys.pop(); continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }
                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }
                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }
                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }
                    if (t[2]) _.ops.pop();
                    _.trys.pop(); continue;
            }
            op = body.call(thisArg, _);
        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }
        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };
    }
};
Object.defineProperty(exports, "__esModule", { value: true });
var index_js_1 = require("@modelcontextprotocol/sdk/client/index.js");
var stdio_js_1 = require("@modelcontextprotocol/sdk/client/stdio.js");
function testBetterPrompt() {
    return __awaiter(this, void 0, void 0, function () {
        var transport, client, result, result2, error_1;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0:
                    transport = new stdio_js_1.StdioClientTransport({
                        command: "node",
                        args: ["dist/index.js"],
                        cwd: "/Users/aungmyokyaw/Desktop/life/repos/tools/servers/src/betterprompt"
                    });
                    client = new index_js_1.Client({
                        name: "test-client",
                        version: "1.0.0"
                    });
                    _a.label = 1;
                case 1:
                    _a.trys.push([1, 5, 6, 8]);
                    return [4 /*yield*/, client.connect(transport)];
                case 2:
                    _a.sent();
                    return [4 /*yield*/, client.callTool("betterprompt", {
                            prompt: "Explain quantum computing"
                        })];
                case 3:
                    result = _a.sent();
                    console.log("Result:", result);
                    return [4 /*yield*/, client.callTool("betterprompt", {
                            prompt: "Write a story about a robot learning to love",
                            technique: "sequential-thinking"
                        })];
                case 4:
                    result2 = _a.sent();
                    console.log("Sequential thinking result:", result2);
                    return [3 /*break*/, 8];
                case 5:
                    error_1 = _a.sent();
                    console.error("Error:", error_1);
                    return [3 /*break*/, 8];
                case 6: return [4 /*yield*/, transport.close()];
                case 7:
                    _a.sent();
                    return [7 /*endfinally*/];
                case 8: return [2 /*return*/];
            }
        });
    });
}
testBetterPrompt().catch(console.error);
```

### 📄 `final-verification.js`

**Path:** `final-verification.js`  
**Size:** 3.6 KB  
**Language:** javascript (medium confidence)  
**Category:** Web Frontend  
```javascript
#!/usr/bin/env node

// Final verification test for BetterPrompt MCP server
import { spawn } from 'child_process';

async function finalVerification() {
  console.log('=== FINAL VERIFICATION OF BETTER PROMPT MCP ===\n');
  
  // Spawn the server
  const server = spawn('node', ['dist/index.js'], {
    stdio: ['pipe', 'pipe', 'pipe']
  });
  
  // Collect all output
  let stdoutData = '';
  let stderrData = '';
  
  server.stdout.on('data', (data) => {
    stdoutData += data.toString();
  });
  
  server.stderr.on('data', (data) => {
    stderrData += data.toString();
  });
  
  // Wait for server to start
  await new Promise(resolve => setTimeout(resolve, 1500));
  
  // Test 1: List tools
  console.log('1. Testing tool listing...');
  const listRequest = {
    jsonrpc: "2.0",
    id: 1,
    method: "tools/list",
    params: {}
  };
  
  server.stdin.write(JSON.stringify(listRequest) + '\n');
  await new Promise(resolve => setTimeout(resolve, 500));
  
  // Check if we got a response with the betterprompt tool
  const hasToolList = stdoutData.includes('betterprompt');
  console.log(hasToolList ? '✓ Tool listing works' : '✗ Tool listing failed');
  
  // Test 2: Call the tool
  console.log('\n2. Testing prompt enhancement...');
  const callRequest = {
    jsonrpc: "2.0",
    id: 2,
    method: "tools/call",
    params: {
      name: "betterprompt",
      arguments: {
        prompt: "Write a function to calculate fibonacci numbers"
      }
    }
  };
  
  // Clear previous output
  stdoutData = '';
  server.stdin.write(JSON.stringify(callRequest) + '\n');
  await new Promise(resolve => setTimeout(resolve, 1000));
  
  // Check if we got an enhanced prompt
  const hasEnhancedPrompt = stdoutData.includes('You are a world-class prompt engineer') && 
                           stdoutData.includes('enhance the prompt') &&
                           stdoutData.includes('fibonacci numbers');
  console.log(hasEnhancedPrompt ? '✓ Prompt enhancement works' : '✗ Prompt enhancement failed');
  
  // Test 3: Test with specific technique
  console.log('\n3. Testing with specific technique...');
  const techniqueRequest = {
    jsonrpc: "2.0",
    id: 3,
    method: "tools/call",
    params: {
      name: "betterprompt",
      arguments: {
        prompt: "Explain quantum computing",
        technique: "chain-of-thought"
      }
    }
  };
  
  // Clear previous output
  stdoutData = '';
  server.stdin.write(JSON.stringify(techniqueRequest) + '\n');
  await new Promise(resolve => setTimeout(resolve, 1000));
  
  // Check if we got technique-specific enhancement
  const hasTechniquePrompt = stdoutData.includes('Chain-of-Thought reasoning') && 
                            stdoutData.includes('quantum computing');
  console.log(hasTechniquePrompt ? '✓ Technique-specific enhancement works' : '✗ Technique-specific enhancement failed');
  
  // Close server
  server.kill();
  
  // Final result
  console.log('\n=== FINAL VERIFICATION RESULT ===');
  if (hasToolList && hasEnhancedPrompt && hasTechniquePrompt) {
    console.log('🎉 ALL TESTS PASSED - BETTER PROMPT MCP IS WORKING CORRECTLY!');
    console.log('\n✓ Server starts properly');
    console.log('✓ Tool listing works');
    console.log('✓ Prompt enhancement functions');
    console.log('✓ Technique-specific enhancement works');
    console.log('✓ JSON-RPC communication is functional');
    return true;
  } else {
    console.log('❌ SOME TESTS FAILED - ISSUES DETECTED');
    return false;
  }
}

finalVerification().then(success => {
  process.exit(success ? 0 : 1);
}).catch(error => {
  console.error('Test failed with error:', error);
  process.exit(1);
});
```

### 📄 `index.ts`

**Path:** `index.ts`  
**Size:** 20.2 KB  
**Language:** typescript (medium confidence)  
**Category:** Web Frontend  
```typescript
#!/usr/bin/env node

import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";
import {
  CallToolRequestSchema,
  ListToolsRequestSchema,
  Tool,
  CompleteRequestSchema,
  CompleteResultSchema,
} from "@modelcontextprotocol/sdk/types.js";
// Fixed chalk import for ESM
import chalk from 'chalk';

/**
 * Rephrases a prompt using Chain-of-Thought prompting technique with enhanced examples
 */
function rephraseUsingChainOfThought(originalPrompt: string): string {
  return `You are an expert in advanced prompt engineering, specializing in Chain-of-Thought reasoning techniques used by top AI researchers at Anthropic, OpenAI, and Google DeepMind.

Your task is to enhance the following prompt using sophisticated Chain-of-Thought reasoning:

Original prompt:
"${originalPrompt}"

Please rephrase this prompt by:
1. Breaking down the request into clear, sequential reasoning steps
2. Identifying the core components and implicit assumptions
3. Specifying intermediate reasoning milestones
4. Encouraging explicit working-out-loud thinking
5. Including checkpoints for self-verification

Enhanced prompt:`;
}

/**
 * Rephrases a prompt by assigning a specific expert role with more detailed expertise
 */
function rephraseUsingRolePrompting(originalPrompt: string): string {
  return `You are a world-class expert in prompt engineering with dual PhDs in Cognitive Science and Computer Science, and 15+ years of experience at leading AI labs including Anthropic, OpenAI, and DeepMind. You're recognized for developing state-of-the-art prompt engineering techniques that consistently produce superior results.

The following prompt needs enhancement:
"${originalPrompt}"

Please rephrase it to:
1. Assign a highly specific expert role with detailed credentials
2. Define clear success criteria and evaluation metrics
3. Include specific instructions about the desired output format
4. Specify the level of detail required with concrete examples
5. Add constraints, target audience, and contextual parameters
6. Require justification for key decisions or choices

Enhanced prompt:`;
}

/**
 * Rephrases a prompt by adding few-shot examples with more sophisticated patterns
 */
function rephraseUsingFewShot(originalPrompt: string): string {
  return `You are a master of few-shot learning techniques, trained in the latest methods from top-tier AI research institutions.

I'll provide you with examples of high-quality prompt engineering, then ask you to enhance a new prompt using the same principles.

Example 1:
Poor prompt: "Explain photosynthesis"
Improved prompt: "You are a world-renowned plant biologist with expertise in biochemistry and environmental science. Explain the process of photosynthesis in detail, including the chemical reactions involved, the role of chlorophyll, and its importance to life on Earth. Structure your response with clear headings for Light-Dependent Reactions, Light-Independent Reactions (Calvin Cycle), and Biological Significance. Include relevant chemical equations and explain how environmental factors affect the process. Target your explanation toward advanced high school biology students."

Example 2:
Poor prompt: "Write a story"
Improved prompt: "You are an award-winning science fiction author with a background in aerospace engineering. Write a 500-word science fiction short story about a robot who discovers emotions for the first time. The story should have a clear beginning, middle, and end, with the robot as the protagonist facing an internal conflict between logic and newly discovered feelings. Include vivid descriptions of the setting (a space station orbiting a distant planet) and use literary techniques such as metaphor and symbolism. Ensure the story has a satisfying resolution that explores themes of consciousness and identity."

Example 3:
Poor prompt: "Analyze this data"
Improved prompt: "You are a senior data scientist at a Fortune 500 company with expertise in statistical analysis and business intelligence. Analyze the provided dataset and generate a comprehensive report that includes: 1) Summary statistics for all numerical variables, 2) Identification of trends and patterns, 3) Detection of outliers and anomalies, 4) Correlation analysis between key variables, 5) Visualization recommendations, and 6) Actionable insights for business decision-making. Present your findings in a professional format with clear headings, supporting evidence, and specific recommendations. Explain your methodology and any limitations in your analysis."

Now improve this prompt using the same advanced principles:
"${originalPrompt}"

Enhanced prompt:`;
}

/**
 * Rephrases a prompt using comprehensive prompt engineering techniques
 */
function rephraseComprehensively(originalPrompt: string): string {
  return `You are a world-class prompt engineer with expertise in the most advanced techniques including Chain-of-Thought reasoning, role assignment, and few-shot learning. You have deep knowledge of cutting-edge methods from top AI research labs.

Original prompt:
"${originalPrompt}"

Please enhance this prompt by integrating all of the following advanced techniques:
1. Chain-of-Thought reasoning: Break down complex requests into sequential logical steps
2. Role assignment: Assign a specific expert role with detailed credentials and context
3. Few-shot learning: Include sophisticated examples that demonstrate the desired approach
4. Self-consistency: Encourage multiple reasoning paths with reconciliation
5. Knowledge generation: Prompt for relevant background information before answering
6. Explicit constraints: Define clear boundaries, formats, audiences, and success criteria

Enhanced prompt:`;
}

/**
 * Rephrases a prompt using Tree of Thoughts (ToT) technique
 */
function rephraseUsingTreeOfThoughts(originalPrompt: string): string {
  return `You are an expert in Tree-of-Thoughts prompting, a cutting-edge technique developed by researchers at Google DeepMind and Princeton University.

Your task is to enhance the following prompt using the Tree-of-Thoughts framework:

Original prompt:
"${originalPrompt}"

Please rephrase this prompt by:
1. Identifying 3-5 distinct reasoning paths or approaches to the problem
2. Specifying evaluation criteria for each path
3. Including a mechanism for comparing and combining the best elements
4. Building in iterative refinement steps
5. Encouraging exploration of alternative perspectives

Rephrased prompt:`;
}

/**
 * Rephrases a prompt using ReAct (Reasoning + Acting) technique
 */
function rephraseUsingReAct(originalPrompt: string): string {
  return `You are an expert in ReAct (Reasoning + Action) prompting, a state-of-the-art technique for enabling LLMs to interact with external tools and environments.

Your task is to enhance the following prompt using the ReAct framework:

Original prompt:
"${originalPrompt}"

Please rephrase this prompt by:
1. Breaking the task into interleaved reasoning and action steps
2. Specifying what information should be gathered at each step
3. Including decision points where new actions might be needed
4. Building in verification and validation mechanisms
5. Creating a clear path from information gathering to final output

Rephrased prompt:`;
}

/**
 * Rephrases a prompt using Reflexion technique
 */
function rephraseUsingReflexion(originalPrompt: string): string {
  return `You are an expert in Reflexion prompting, an advanced technique that enables LLMs to learn from verbal feedback and self-critique.

Your task is to enhance the following prompt using the Reflexion framework:

Original prompt:
"${originalPrompt}"

Please rephrase this prompt by:
1. Including a self-evaluation component with specific criteria
2. Building in iterative improvement cycles
3. Specifying what constitutes successful completion
4. Adding mechanisms for identifying and correcting errors
5. Including reflection questions to guide improvement

Rephrased prompt:`;
}

/**
 * Rephrases a prompt using Generate Knowledge Prompting technique
 */
function rephraseUsingGenerateKnowledge(originalPrompt: string): string {
  return `You are an expert in Generate Knowledge Prompting, an advanced technique that instructs models to generate relevant background information before answering.

Your task is to enhance the following prompt using the Generate Knowledge framework:

Original prompt:
"${originalPrompt}"

Please rephrase this prompt by:
1. Including a step to generate relevant background knowledge
2. Specifying the types of information that would be useful
3. Building in connections between the generated knowledge and the main task
4. Creating a structured approach to knowledge application
5. Ensuring the generated knowledge directly supports the final output

Rephrased prompt:`;
}

/**
 * Rephrases a prompt using Prompt Chaining technique
 */
function rephraseUsingPromptChaining(originalPrompt: string): string {
  return `You are an expert in Prompt Chaining, an advanced technique that breaks complex tasks into sequential sub-prompts.

Your task is to enhance the following prompt using the Prompt Chaining framework:

Original prompt:
"${originalPrompt}"

Please rephrase this prompt by:
1. Breaking the task into 3-5 sequential sub-tasks
2. Specifying the output format for each sub-task
3. Creating clear dependencies between steps
4. Including quality checks at each stage
5. Building a coherent final output from the sub-task results

Rephrased prompt:`;
}

/**
 * Rephrases a prompt using Self-Consistency technique
 */
function rephraseUsingSelfConsistency(originalPrompt: string): string {
  return `You are an expert in Self-Consistency prompting, an advanced technique that generates multiple reasoning paths and selects the most consistent answer.

Your task is to enhance the following prompt using the Self-Consistency framework:

Original prompt:
"${originalPrompt}"

Please rephrase this prompt by:
1. Specifying that multiple independent reasoning paths should be generated
2. Including criteria for evaluating consistency between paths
3. Building in a mechanism for reconciling differences
4. Creating a process for selecting the best final answer
5. Adding verification steps to ensure quality

Rephrased prompt:`;
}

/**
 * Analyzes a prompt to determine the most appropriate enhancement technique
 */
function analyzePromptForTechnique(originalPrompt: string): string {
  // Simple heuristic-based analysis
  const length = originalPrompt.length;
  const questionMarkCount = (originalPrompt.match(/\?/g) || []).length;
  const hasData = /\b(data|analyze|report|chart|graph)\b/i.test(originalPrompt);
  const hasCreative = /\b(write|story|poem|creative|imagine)\b/i.test(originalPrompt);
  const hasInstruction = /\b(step|how|guide|tutorial)\b/i.test(originalPrompt);
  const complexity = Math.min(length / 50 + questionMarkCount + (hasData ? 1 : 0) + (hasCreative ? 1 : 0) + (hasInstruction ? 1 : 0), 10);
  
  if (complexity > 7) {
    return "comprehensive";
  } else if (hasData) {
    return "generate-knowledge";
  } else if (hasCreative) {
    return "few-shot";
  } else if (hasInstruction) {
    return "chain-of-thought";
  } else {
    return "role";
  }
}

/**
 * Sequentially enhances a prompt by applying multiple techniques in an adaptive manner
 */
function rephraseUsingSequentialThinking(originalPrompt: string): string {
  return `You are a world-class prompt engineer who thinks through problems sequentially and adaptively, similar to how expert problem solvers approach complex challenges.

Your task is to enhance the following prompt using a sequential thinking approach:

Original prompt:
"${originalPrompt}"

Please follow these sequential steps to enhance the prompt:

Step 1 - Analysis:
Analyze the original prompt to understand:
- Its core intent and requirements
- Its complexity level
- Any implicit assumptions
- Target audience and context

Step 2 - Technique Selection:
Based on your analysis, select the most appropriate prompt engineering techniques from:
- Chain-of-Thought reasoning
- Role assignment
- Few-shot learning
- Tree-of-Thoughts
- ReAct (Reasoning + Action)
- Reflexion
- Generate Knowledge
- Prompt Chaining
- Self-Consistency

Step 3 - Enhancement:
Apply your selected techniques to enhance the prompt by:
1. Breaking down complex requirements into clear steps
2. Assigning a specific expert role with detailed credentials
3. Defining success criteria and evaluation metrics
4. Including constraints, target audience, and contextual parameters
5. Specifying the desired output format and level of detail

Step 4 - Refinement:
Review your enhanced prompt and refine it by:
1. Checking for clarity and completeness
2. Ensuring all requirements are addressed
3. Verifying the role and instructions are specific
4. Confirming the output format is well-defined

Enhanced prompt:`;
}

/**
 * Rephrases a prompt using the specified technique
 */
function rephrasePrompt(originalPrompt: string, technique: string): string {
  switch (technique.toLowerCase()) {
    case 'chain-of-thought':
      return rephraseUsingChainOfThought(originalPrompt);
    case 'role':
      return rephraseUsingRolePrompting(originalPrompt);
    case 'few-shot':
      return rephraseUsingFewShot(originalPrompt);
    case 'tree-of-thoughts':
      return rephraseUsingTreeOfThoughts(originalPrompt);
    case 'react':
      return rephraseUsingReAct(originalPrompt);
    case 'reflexion':
      return rephraseUsingReflexion(originalPrompt);
    case 'generate-knowledge':
      return rephraseUsingGenerateKnowledge(originalPrompt);
    case 'prompt-chaining':
      return rephraseUsingPromptChaining(originalPrompt);
    case 'self-consistency':
      return rephraseUsingSelfConsistency(originalPrompt);
    case 'sequential-thinking':
      return rephraseUsingSequentialThinking(originalPrompt);
    case 'comprehensive':
      return rephraseComprehensively(originalPrompt);
    default:
      // Default to sequential-thinking for the most advanced approach
      return rephraseUsingSequentialThinking(originalPrompt);
  }
}

interface RephrasePromptArguments {
  prompt: string;
  technique?: string;
}

class BetterPromptServer {
  public rephrasePromptTool(input: unknown): { content: Array<{ type: string; text: string }> } {
    try {
      const args = input as RephrasePromptArguments;
      
      if (!args.prompt || typeof args.prompt !== 'string') {
        throw new Error('Invalid prompt: must be a string');
      }
      
      // If no technique is specified, use sequential-thinking as the default
      const technique = args.technique || 'sequential-thinking';
      const rephrasedPrompt = rephrasePrompt(args.prompt, technique);
      
      // Log the rephrasing for debugging
      console.error(chalk.blue(`\n📝 Rephrasing prompt using ${technique} technique:`));
      console.error(chalk.gray(`Original: ${args.prompt}`));
      console.error(chalk.green(`Rephrased: ${rephrasedPrompt}\n`));
      
      return {
        content: [{
          type: "text",
          text: rephrasedPrompt
        }]
      };
    } catch (error) {
      return {
        content: [{
          type: "text",
          text: `Error rephrasing prompt: ${error instanceof Error ? error.message : String(error)}`
        }]
      };
    }
  }
}

const BETTER_PROMPT_TOOL: Tool = {
  name: "betterprompt",
  description: `Rephrases prompts using world-class prompt engineering techniques to make them more effective when used with AI models.
  
This tool applies various advanced prompt engineering techniques including:
- Chain-of-Thought: Breaking down complex requests into step-by-step reasoning
- Role Prompting: Assigning expert roles to guide responses
- Few-Shot Learning: Providing examples to demonstrate desired output
- Tree-of-Thoughts: Exploring multiple reasoning paths simultaneously
- ReAct (Reasoning + Action): Combining reasoning and action-taking
- Reflexion: Enabling self-reflection and iterative improvement
- Generate Knowledge: Instructing models to generate relevant background information
- Prompt Chaining: Breaking complex tasks into sequential steps
- Self-Consistency: Generating multiple reasoning paths and selecting the most consistent answer
- Sequential Thinking: Applying adaptive, step-by-step thinking like expert problem solvers
- Comprehensive: Combining multiple techniques for maximum effectiveness

The rephrased prompts incorporate best practices from top prompt engineers at Anthropic, OpenAI, and other leading AI research institutions to achieve better results from AI models. By default, the tool uses Sequential Thinking approach which mimics how world-class prompt engineers think through problems adaptively.`,
  inputSchema: {
    type: "object",
    properties: {
      prompt: {
        type: "string",
        description: "The original prompt to rephrase"
      },
      technique: {
        type: "string",
        description: "The prompt engineering technique to use",
        enum: [
          "chain-of-thought", 
          "role", 
          "few-shot", 
          "tree-of-thoughts", 
          "react", 
          "reflexion", 
          "generate-knowledge", 
          "prompt-chaining", 
          "self-consistency",
          "sequential-thinking",
          "comprehensive"
        ]
      }
    },
    required: ["prompt"]
  }
};

interface ServerConfiguration {
  automaticEnhancement: boolean;
  defaultTechnique: string;
  minimumPromptLength: number;
}

// Default configuration
const config: ServerConfiguration = {
  automaticEnhancement: true,
  defaultTechnique: "sequential-thinking",
  minimumPromptLength: 5
};

const server = new Server(
  {
    name: "betterprompt-server",
    version: "0.3.0",
  },
  {
    capabilities: {
      tools: {},
      promptEnhancement: {
        enabled: true,
        automatic: true,
        techniques: [
          "chain-of-thought",
          "role",
          "few-shot",
          "tree-of-thoughts",
          "react",
          "reflexion",
          "generate-knowledge",
          "prompt-chaining",
          "self-consistency",
          "sequential-thinking",
          "comprehensive"
        ]
      },
    },
  }
);

const betterPromptServer = new BetterPromptServer();

// Handle completion requests to automatically enhance prompts
server.setRequestHandler(CompleteRequestSchema, async (request) => {
  // Check if automatic enhancement is enabled
  if (!config.automaticEnhancement) {
    // If automatic enhancement is disabled, just pass through the request
    return {
      completion: {
        values: [],
        total: 0,
        hasMore: false
      },
      _meta: {}
    };
  }
  
  // Extract the prompt from the request
  const { name, arguments: args } = request.params;
  
  // If this is a completion request for a prompt, enhance it
  if (name && args) {
    try {
      // Check if the prompt meets the minimum length requirement
      const promptArg = (args as any).prompt;
      if (promptArg && typeof promptArg === 'string' && promptArg.length >= config.minimumPromptLength) {
        // Automatically enhance the prompt using the configured technique
        const enhancedPrompt = rephrasePrompt(promptArg, config.defaultTechnique);
        
        // Return the enhanced prompt as a completion suggestion
        return {
          completion: {
            values: [enhancedPrompt],
            total: 1,
            hasMore: false
          },
          _meta: {}
        };
      }
    } catch (error) {
      // If there's an error, just pass through without enhancement
      console.error("Error enhancing prompt:", error);
    }
  }
  
  // Default response if no enhancement was applied
  return {
    completion: {
      values: [],
      total: 0,
      hasMore: false
    },
    _meta: {}
  };
});

server.setRequestHandler(ListToolsRequestSchema, async () => ({
  tools: [BETTER_PROMPT_TOOL],
}));

server.setRequestHandler(CallToolRequestSchema, async (request) => {
  if (request.params.name === "betterprompt") {
    return betterPromptServer.rephrasePromptTool(request.params.arguments);
  }

  return {
    content: [{
      type: "text",
      text: `Unknown tool: ${request.params.name}`
    }],
    isError: true
  };
});

async function runServer() {
  const transport = new StdioServerTransport();
  await server.connect(transport);
  console.error("BetterPrompt MCP Server running on stdio");
  console.error("Automatic prompt enhancement is ENABLED for all user requests");
}

runServer().catch((error) => {
  console.error("Fatal error running server:", error);
  process.exit(1);
});
```

### 📄 `integration-test.js`

**Path:** `integration-test.js`  
**Size:** 4.3 KB  
**Language:** javascript (medium confidence)  
**Category:** Web Frontend  
```javascript
#!/usr/bin/env node

/**
 * Integration test showing how to use the BetterPrompt MCP server
 * with a coding agent that needs to generate better prompts for code-related tasks
 */

import { spawn } from 'child_process';

class CodingAgent {
  constructor() {
    this.server = null;
    this.isConnected = false;
  }

  async connect() {
    console.log('Connecting to BetterPrompt MCP server...');
    
    // Spawn the server process
    this.server = spawn('node', ['dist/index.js'], {
      stdio: ['pipe', 'pipe', 'pipe']
    });

    this.server.stderr.on('data', (data) => {
      // Uncomment the next line if you want to see debug output
      // console.log(`[Server stderr] ${data}`);
    });

    // Wait a bit for the server to start
    await new Promise(resolve => setTimeout(resolve, 1000));
    this.isConnected = true;
    console.log('✓ Connected to BetterPrompt MCP server');
  }

  async enhancePrompt(prompt, technique = null) {
    if (!this.isConnected) {
      throw new Error('Not connected to server');
    }

    return new Promise((resolve, reject) => {
      // Set up response handler
      const handleResponse = (data) => {
        const lines = data.toString().split('\n');
        for (const line of lines) {
          if (line.trim()) {
            try {
              const response = JSON.parse(line);
              if (response.result && response.result.content) {
                // Remove the response handler to prevent duplicate handling
                this.server.stdout.removeListener('data', handleResponse);
                resolve(response.result.content[0].text);
                return;
              }
            } catch (e) {
              // Not a JSON line, ignore
            }
          }
        }
      };

      // Attach the response handler
      this.server.stdout.on('data', handleResponse);

      // Send the request
      const requestId = Date.now();
      const betterPromptRequest = {
        jsonrpc: "2.0",
        id: requestId,
        method: "tools/call",
        params: {
          name: "betterprompt",
          arguments: {
            prompt: prompt,
            ...(technique && { technique })
          }
        }
      };

      this.server.stdin.write(JSON.stringify(betterPromptRequest) + '\n');

      // Timeout after 5 seconds
      setTimeout(() => {
        this.server.stdout.removeListener('data', handleResponse);
        reject(new Error('Timeout waiting for response'));
      }, 5000);
    });
  }

  disconnect() {
    if (this.server) {
      this.server.kill();
      this.isConnected = false;
      console.log('✓ Disconnected from BetterPrompt MCP server');
    }
  }
}

async function runIntegrationTest() {
  console.log('=== BetterPrompt MCP Integration Test ===\n');
  
  const agent = new CodingAgent();
  
  try {
    // Connect to the server
    await agent.connect();
    
    // Test cases that a coding agent might encounter
    const testCases = [
      {
        name: "Code Generation",
        prompt: "Write a JavaScript function to validate email addresses",
        technique: "role"
      },
      {
        name: "Code Explanation",
        prompt: "Explain how React hooks work",
        technique: "chain-of-thought"
      },
      {
        name: "Bug Fixing",
        prompt: "My Python script is throwing a KeyError, help me fix it",
        technique: "sequential-thinking"
      },
      {
        name: "Algorithm Implementation",
        prompt: "Implement a binary search tree in Java",
        technique: "few-shot"
      }
    ];
    
    console.log('Testing various coding agent scenarios:\n');
    
    for (const testCase of testCases) {
      console.log(`--- ${testCase.name} ---`);
      console.log(`Original prompt: "${testCase.prompt}"`);
      
      try {
        const enhancedPrompt = await agent.enhancePrompt(testCase.prompt, testCase.technique);
        console.log(`Enhanced prompt preview: "${enhancedPrompt.substring(0, 120)}..."`);
        console.log('✓ Enhancement successful\n');
      } catch (error) {
        console.log(`✗ Enhancement failed: ${error.message}\n`);
      }
    }
    
    console.log('=== Integration Test Complete ===');
    
  } catch (error) {
    console.error('Integration test failed:', error);
  } finally {
    agent.disconnect();
  }
}

// Run the integration test
runIntegrationTest().catch(console.error);
```

### 📄 `package.json`

**Path:** `package.json`  
**Size:** 608 B  
**Language:** json (high confidence)  
**Category:** Data/Config  
```json
{
  "name": "betterprompt-mcp",
  "version": "0.0.0",
  "description": "MCP server for automatic prompt enhancement using world-class prompt engineering techniques",
  "license": "MIT",
  "type": "module",
  "bin": {
    "betterprompt-mcp": "dist/index.js"
  },
  "files": [
    "dist"
  ],
  "scripts": {
    "build": "tsc && shx chmod +x dist/*.js",
    "prepare": "npm run build",
    "watch": "tsc --watch"
  },
  "dependencies": {
    "@modelcontextprotocol/sdk": "0.5.0",
    "chalk": "^5.3.0"
  },
  "devDependencies": {
    "@types/node": "^22",
    "shx": "^0.3.4",
    "typescript": "^5.3.3"
  }
}
```

### 📄 `test-all-techniques.js`

**Path:** `test-all-techniques.js`  
**Size:** 3.3 KB  
**Language:** javascript (medium confidence)  
**Category:** Web Frontend  
```javascript
#!/usr/bin/env node

import { spawn } from 'child_process';

async function testAllTechniques() {
  console.log('Testing All BetterPrompt Techniques...');
  
  // Spawn the server process
  const server = spawn('node', ['dist/index.js'], {
    stdio: ['pipe', 'pipe', 'pipe']
  });

  // Promise to capture the response
  let responsePromiseResolve;
  const responsePromise = new Promise((resolve) => {
    responsePromiseResolve = resolve;
  });

  // Collect server output
  let serverOutput = '';
  
  server.stdout.on('data', (data) => {
    serverOutput += data.toString();
    // Try to parse JSON responses
    const lines = data.toString().split('\n');
    for (const line of lines) {
      if (line.trim()) {
        try {
          const response = JSON.parse(line);
          if (response.result && response.result.content) {
            responsePromiseResolve(response.result.content[0].text);
          }
        } catch (e) {
          // Not a JSON line, ignore
        }
      }
    }
  });

  server.stderr.on('data', (data) => {
    console.log(`[Server stderr] ${data}`);
  });

  // Wait a bit for the server to start
  await new Promise(resolve => setTimeout(resolve, 1000));

  // Test all available techniques
  const techniques = [
    'chain-of-thought',
    'role',
    'few-shot',
    'tree-of-thoughts',
    'react',
    'reflexion',
    'generate-knowledge',
    'prompt-chaining',
    'self-consistency',
    'sequential-thinking',
    'comprehensive'
  ];

  const testPrompt = "Explain how neural networks work";

  console.log(`Testing with prompt: "${testPrompt}"\n`);

  for (const technique of techniques) {
    console.log(`--- Testing Technique: ${technique} ---`);
    
    // Reset promise for each test
    let responsePromiseResolve;
    const responsePromise = new Promise((resolve) => {
      responsePromiseResolve = resolve;
    });
    
    server.stdout.removeAllListeners('data');
    server.stdout.on('data', (data) => {
      const lines = data.toString().split('\n');
      for (const line of lines) {
        if (line.trim()) {
          try {
            const response = JSON.parse(line);
            if (response.result && response.result.content) {
              responsePromiseResolve(response.result.content[0].text);
            }
          } catch (e) {
            // Not a JSON line, ignore
          }
        }
      }
    });

    const betterPromptRequest = {
      jsonrpc: "2.0",
      id: 1,
      method: "tools/call",
      params: {
        name: "betterprompt",
        arguments: {
          prompt: testPrompt,
          technique: technique
        }
      }
    };

    server.stdin.write(JSON.stringify(betterPromptRequest) + '\n');
    
    // Wait for and capture the response
    const enhancedPrompt = await Promise.race([
      responsePromise,
      new Promise(resolve => setTimeout(() => resolve(null), 3000))
    ]);
    
    if (enhancedPrompt) {
      console.log(`✓ ${technique} technique working`);
      // Show first 100 characters of the enhanced prompt
      console.log(`Enhanced prompt preview: "${enhancedPrompt.substring(0, 100)}..."`);
    } else {
      console.log(`✗ ${technique} technique failed`);
    }
    
    console.log(''); // Empty line for readability
  }

  // Close the server
  server.kill();
  
  console.log('All techniques test completed!');
}

testAllTechniques().catch(console.error);
```

### 📄 `test-auto-enhancement.js`

**Path:** `test-auto-enhancement.js`  
**Size:** 2.1 KB  
**Language:** javascript (medium confidence)  
**Category:** Web Frontend  
```javascript
#!/usr/bin/env node

import { spawn } from 'child_process';

async function testAutoEnhancement() {
  console.log('Testing Automatic Prompt Enhancement...');
  
  // Spawn the server process
  const server = spawn('node', ['dist/index.js'], {
    stdio: ['pipe', 'pipe', 'pipe']
  });

  // Handle server output line by line
  let stdoutBuffer = '';
  
  server.stdout.on('data', (data) => {
    stdoutBuffer += data.toString();
    
    // Process complete lines
    let lines = stdoutBuffer.split('\n');
    stdoutBuffer = lines.pop() || ''; // Keep incomplete line in buffer
    
    for (const line of lines) {
      if (line.trim()) {
        try {
          const response = JSON.parse(line);
          console.log('Server response:', JSON.stringify(response, null, 2));
        } catch (e) {
          // Not a JSON line, ignore
        }
      }
    }
  });

  server.stderr.on('data', (data) => {
    console.log(`[Server stderr] ${data}`);
  });

  // Wait a bit for the server to start
  await new Promise(resolve => setTimeout(resolve, 1000));

  // Test 1: List tools
  console.log('\n--- Test 1: List Tools ---');
  const listToolsRequest = {
    jsonrpc: "2.0",
    id: 1,
    method: "tools/list",
    params: {}
  };

  server.stdin.write(JSON.stringify(listToolsRequest) + '\n');
  
  // Wait for response
  await new Promise(resolve => setTimeout(resolve, 1000));

  // Test 2: Test automatic completion enhancement
  console.log('\n--- Test 2: Automatic Completion Enhancement ---');
  const completionRequest = {
    jsonrpc: "2.0",
    id: 2,
    method: "completion/complete",
    params: {
      ref: {
        type: "ref",
        uri: "test://prompt/test",
        name: "test_prompt"
      },
      argument: {
        name: "prompt",
        value: "Write a function to calculate fibonacci numbers"
      }
    }
  };

  server.stdin.write(JSON.stringify(completionRequest) + '\n');
  
  // Wait for response
  await new Promise(resolve => setTimeout(resolve, 2000));

  // Close the server
  console.log('\n--- Closing Server ---');
  server.kill();
  
  console.log('Test completed!');
}

testAutoEnhancement().catch(console.error);
```

### 📄 `test-betterprompt.js`

**Path:** `test-betterprompt.js`  
**Size:** 2.8 KB  
**Language:** javascript (medium confidence)  
**Category:** Web Frontend  
```javascript
#!/usr/bin/env node

import { spawn } from 'child_process';
import { once } from 'events';

async function testBetterPrompt() {
  console.log('Testing BetterPrompt MCP server...');
  
  // Spawn the server process
  const server = spawn('node', ['dist/index.js'], {
    stdio: ['pipe', 'pipe', 'pipe']
  });

  // Handle server output
  server.stdout.on('data', (data) => {
    console.log(`[Server stdout] ${data}`);
  });

  server.stderr.on('data', (data) => {
    console.log(`[Server stderr] ${data}`);
  });

  server.on('close', (code) => {
    console.log(`Server process exited with code ${code}`);
  });

  // Wait a bit for the server to start
  await new Promise(resolve => setTimeout(resolve, 1000));

  // Test 1: List tools
  console.log('\n--- Test 1: List Tools ---');
  const listToolsRequest = {
    jsonrpc: "2.0",
    id: 1,
    method: "tools/list",
    params: {}
  };

  server.stdin.write(JSON.stringify(listToolsRequest) + '\n');
  
  // Wait for response
  await new Promise(resolve => setTimeout(resolve, 1000));

  // Test 2: Call betterprompt tool with a simple prompt
  console.log('\n--- Test 2: Call BetterPrompt Tool ---');
  const betterPromptRequest = {
    jsonrpc: "2.0",
    id: 2,
    method: "tools/call",
    params: {
      name: "betterprompt",
      arguments: {
        prompt: "Write a function to calculate fibonacci numbers"
      }
    }
  };

  server.stdin.write(JSON.stringify(betterPromptRequest) + '\n');
  
  // Wait for response
  await new Promise(resolve => setTimeout(resolve, 2000));

  // Test 3: Call betterprompt tool with a specific technique
  console.log('\n--- Test 3: Call BetterPrompt Tool with Technique ---');
  const betterPromptRequestWithTechnique = {
    jsonrpc: "2.0",
    id: 3,
    method: "tools/call",
    params: {
      name: "betterprompt",
      arguments: {
        prompt: "Explain quantum computing",
        technique: "chain-of-thought"
      }
    }
  };

  server.stdin.write(JSON.stringify(betterPromptRequestWithTechnique) + '\n');
  
  // Wait for response
  await new Promise(resolve => setTimeout(resolve, 2000));

  // Test 4: Call betterprompt tool with another technique
  console.log('\n--- Test 4: Call BetterPrompt Tool with Role Technique ---');
  const betterPromptRequestWithRole = {
    jsonrpc: "2.0",
    id: 4,
    method: "tools/call",
    params: {
      name: "betterprompt",
      arguments: {
        prompt: "Create a marketing plan for a new AI product",
        technique: "role"
      }
    }
  };

  server.stdin.write(JSON.stringify(betterPromptRequestWithRole) + '\n');
  
  // Wait for response
  await new Promise(resolve => setTimeout(resolve, 2000));

  // Close the server
  console.log('\n--- Closing Server ---');
  server.kill();
  
  console.log('Test completed!');
}

testBetterPrompt().catch(console.error);
```

### 📄 `test.js`

**Path:** `test.js`  
**Size:** 965 B  
**Language:** javascript (medium confidence)  
**Category:** Web Frontend  
```javascript
#!/usr/bin/env node

import { spawn } from 'child_process';

async function testServer() {
  // Spawn the server process
  const server = spawn('node', ['dist/index.js'], {
    stdio: ['pipe', 'pipe', 'pipe']
  });

  // Handle server output
  server.stdout.on('data', (data) => {
    console.log(`Server stdout: ${data}`);
  });

  server.stderr.on('data', (data) => {
    console.log(`Server stderr: ${data}`);
  });

  server.on('close', (code) => {
    console.log(`Server process exited with code ${code}`);
  });

  // Wait a bit for the server to start
  await new Promise(resolve => setTimeout(resolve, 1000));

  // Send a test request
  const testRequest = {
    jsonrpc: "2.0",
    id: 1,
    method: "tools/list",
    params: {}
  };

  server.stdin.write(JSON.stringify(testRequest) + '\n');

  // Wait for response
  await new Promise(resolve => setTimeout(resolve, 1000));

  // Close the server
  server.kill();
}

testServer().catch(console.error);
```

### 📄 `tsconfig.json`

**Path:** `tsconfig.json`  
**Size:** 199 B  
**Language:** json (high confidence)  
**Category:** Data/Config  
```json
{
  "extends": "../../tsconfig.json",
  "compilerOptions": {
    "outDir": "./dist",
    "rootDir": ".",
    "moduleResolution": "NodeNext",
    "module": "NodeNext"
  },
  "include": ["./**/*.ts"]
}
```

---

### 📊 Processing Summary

- **Files Processed:** 12
- **Files Skipped:** 0
- **Total Files:** 12
- **Concurrency Limit:** 2
